# ì „ì²´ ì‹¤í–‰ ë¡œì§ í†µí•©: ì „ì²˜ë¦¬ â†’ ìœ ì‚¬ë„ ë¶„ì„ â†’ ëŒ€í‘œê¸°ì‚¬ ì„ ì • ë° ì €ì¥ 
import os
import pandas as pd
from konlpy.tag import Okt
from itertools import combinations
from config import CATEGORY, PERIOD, DATE, THRESHOLD_TITLE, get_file_path, get_dedup_dir
from preprocessing_title import preprocess_titles
from grouping import build_title_similarity_groups
from content_filter import filter_and_pick_representative_by_content

# ----- ê²½ë¡œ ì„¤ì • -----
file_path = get_file_path(PERIOD, DATE, CATEGORY)
dedup_dir = get_dedup_dir(PERIOD, DATE)
dedup_dir.mkdir(parents=True, exist_ok=True)  # ì•ˆì „í•˜ê²Œ ë””ë ‰í† ë¦¬ ìƒì„±

# ----- ë°ì´í„° ë¡œë“œ -----
df = pd.read_csv(file_path)
df['title'] = df['title'].fillna('')
df['content'] = df['content'].fillna('')

# ----- ì œëª© ì „ì²˜ë¦¬ -----
df['clean_title'] = df['title'].apply(preprocess_titles)

# ----- ì œëª© ê¸°ë°˜ ìœ ì‚¬ ê·¸ë£¹ ìƒì„± -----
groups, title_similar_pairs = build_title_similarity_groups(df, threshold=THRESHOLD_TITLE)
print(f"\nğŸ”— ìœ ì‚¬ ê·¸ë£¹ ìˆ˜: {len(groups)}")

# ì œëª© ìœ ì‚¬ë„ ì¶œë ¥
print("\nğŸ“Œ ì œëª© ìœ ì‚¬ë„:")
for i, j, sim in title_similar_pairs:
    index_i = df.index[i] + 1
    index_j = df.index[j] + 1
    title_i = df.iloc[i]["title"]
    title_j = df.iloc[j]["title"]

    print(f" - (index {index_i}, {index_j}) ì œëª© ìœ ì‚¬ë„: {sim:.4f}")
    print(f"   â‘  {title_i}")
    print(f"   â‘¡ {title_j}")
    print ("\n")

# ----- ëŒ€í‘œ ê¸°ì‚¬ ì„ íƒ (ë³¸ë¬¸ ê¸°ë°˜) -----
df.reset_index(drop=True, inplace=True)

rep_ids = []
dup_ids = []
group_reps = {}
group_logs = {}

for group in groups:
    rep, is_duplicate_group, content_log = filter_and_pick_representative_by_content(group, df)
    group_key = frozenset(group)
    group_logs[group_key] = content_log  # â† ìœ ì‚¬ë„ ë¡œê·¸ ì €ì¥
    group_set = group_key

    if not is_duplicate_group:
        rep_ids.extend(group)
        for i in group:
            group_reps[frozenset({i})] = i
        group_reps[group_set] = None
    else:
        if rep is not None:
            rep_ids.append(rep)
            dup_ids.extend([i for i in group if i != rep])
        group_reps[group_set] = rep

# âœ… ìœ ì‚¬ë„ ë¹„êµ ëŒ€ìƒ ì™¸ ê¸°ì‚¬ë“¤ë„ ì¶”ê°€
grouped_indices = set(i for group in groups for i in group)
ungrouped_indices = set(df.index) - grouped_indices
rep_ids.extend(ungrouped_indices)

# âœ… ìµœì¢… deduplicated DataFrame ìƒì„±
df_dedup = df.loc[sorted(set(rep_ids))].copy()

# ê²°ê³¼ ì €ì¥
dedup_filename = f"naver_news_{CATEGORY}_{PERIOD}_{DATE}_deduplicated.csv"
output_path = os.path.join(dedup_dir, dedup_filename)
df_dedup.to_csv(output_path, index=False)

print(f"\nâœ… ë³¸ë¬¸ ìœ ì‚¬ë„ ê¸°ë°˜ ëŒ€í‘œ ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ: {output_path}")
print(f"âœ… ì¤‘ë³µ ì œê±° ê²°ê³¼: {len(df)} â†’ {len(df_dedup)}ê°œ")

# ----- ë¡œê·¸ ì €ì¥ -----
log_path = os.path.join(dedup_dir, f"{CATEGORY}_{PERIOD}_{DATE}_groups.txt")
print("\nğŸ“¦ ìœ ì‚¬ ê¸°ì‚¬ ê·¸ë£¹ ë‚´ìš©:")

with open(log_path, "w", encoding="utf-8") as f:
    for idx, group in enumerate(groups, 1):
        group_key = frozenset(group)
        rep = group_reps.get(group_key)
        content_log = group_logs.get(group_key, "")  # â† ë³¸ë¬¸ ìœ ì‚¬ë„ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°

        f.write("=======================================================\n")
        f.write(f"[ê·¸ë£¹ {idx} - ì´ {len(group)}ê±´]\n")
        print(f"[ê·¸ë£¹ {idx} - ì´ {len(group)}ê±´]")

        for i in sorted(group):
            mark = "âœ… ëŒ€í‘œ" if rep is not None and i == rep else ("âŒ ì œê±°" if rep is not None else "âœ… ìœ ì§€")
            title = df.loc[i, 'title']
            f.write(f" - {mark} {title}\n")
            print(f" - {mark} {title}")

        # ë³¸ë¬¸ ìœ ì‚¬ë„ ë¡œê·¸ ì¶”ê°€
        if content_log:
            f.write(content_log + "\n")
        print()
